{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2 #opencv\n",
    "# import os\n",
    "# import time\n",
    "# import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "data_path_train = \"../dataset/sign_mnist_train.csv\"\n",
    "data_path_test  = \"../dataset/sign_mnist_test.csv\"\n",
    "\n",
    "arr_train = np.loadtxt(data_path_train, dtype=np.float32, delimiter=',', skiprows=1)\n",
    "arr_test = np.loadtxt(data_path_test, dtype=np.float32, delimiter=',', skiprows=1)\n",
    "\n",
    "tensor_train = torch.from_numpy(arr_train)\n",
    "tensor_test = torch.from_numpy(arr_test)\n",
    "\n",
    "# dataset_train = [(row[1:].to(torch.float64).reshape(28, 28).unsqueeze(0), row[0].item()) for row in tensor_train]\n",
    "# dataset_train = [(row[1:].reshape(28, 28).unsqueeze(0), row[0].to(torch.int).item()) for row in tensor_train]\n",
    "dataset_train = [(row[1:].reshape(28, 28).unsqueeze(0), row[0].item()) for row in tensor_train]\n",
    "dataset_test = [(row[1:].reshape(28, 28).unsqueeze(0), row[0].item()) for row in tensor_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imgs = torch.stack([img for (img, label) in dataset_train], dim = 3)\n",
    "# mean_deviation = imgs.view(1, -1).mean(dim=1).item()\n",
    "# standard_deviation = imgs.view(1, -1).std(dim=1).item()\n",
    "# # print(dataset_train.shape())\n",
    "# dataset_train = dataset_train/255.0\n",
    "# dataset_test = dataset_test/255.0\n",
    "\n",
    "dataset_train = [(img/255.0, int(label)) for (img, label) in dataset_train]\n",
    "dataset_test = [(img/255.0, int(label)) for (img, label) in dataset_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.3333, 0.3529, 0.3804, 0.4039, 0.4667, 0.5098, 0.5412, 0.5765,\n",
       "          0.5961, 0.6157, 0.6314, 0.6431, 0.6392, 0.6549, 0.6706, 0.6902,\n",
       "          0.6980, 0.7059, 0.7137, 0.7216, 0.7255, 0.7373, 0.7412, 0.7490,\n",
       "          0.7569, 0.7569, 0.7569, 0.7569],\n",
       "         [0.3373, 0.3529, 0.3765, 0.4078, 0.4784, 0.5137, 0.5490, 0.5765,\n",
       "          0.5961, 0.6157, 0.6353, 0.6510, 0.6863, 0.6588, 0.6941, 0.6980,\n",
       "          0.6784, 0.6941, 0.7333, 0.7216, 0.7373, 0.7490, 0.7529, 0.7569,\n",
       "          0.7608, 0.7647, 0.7647, 0.7647],\n",
       "         [0.3412, 0.3608, 0.3843, 0.4157, 0.4824, 0.5216, 0.5569, 0.5804,\n",
       "          0.6039, 0.6314, 0.6157, 0.7412, 0.8196, 0.6980, 0.7333, 0.7804,\n",
       "          0.6588, 0.4196, 0.6588, 0.7529, 0.7373, 0.7529, 0.7569, 0.7608,\n",
       "          0.7608, 0.7647, 0.7686, 0.7686],\n",
       "         [0.3412, 0.3647, 0.3922, 0.4196, 0.4902, 0.5255, 0.5647, 0.5922,\n",
       "          0.6118, 0.6471, 0.6196, 0.8235, 0.7294, 0.5647, 0.6745, 0.7059,\n",
       "          0.6314, 0.3686, 0.4667, 0.7882, 0.7373, 0.7529, 0.7608, 0.7647,\n",
       "          0.7686, 0.7686, 0.7765, 0.7843],\n",
       "         [0.3451, 0.3686, 0.4000, 0.4353, 0.4980, 0.5294, 0.5725, 0.5961,\n",
       "          0.6157, 0.6392, 0.6510, 0.8510, 0.6706, 0.5059, 0.4392, 0.4706,\n",
       "          0.6235, 0.4392, 0.3922, 0.7725, 0.7490, 0.7569, 0.7647, 0.7725,\n",
       "          0.7804, 0.7804, 0.7843, 0.7843],\n",
       "         [0.3529, 0.3765, 0.4078, 0.4471, 0.5059, 0.5333, 0.5686, 0.6000,\n",
       "          0.6314, 0.6314, 0.7059, 0.8549, 0.6235, 0.5725, 0.2588, 0.5098,\n",
       "          0.6588, 0.5373, 0.3804, 0.6667, 0.7765, 0.7569, 0.7725, 0.7804,\n",
       "          0.7843, 0.7922, 0.7922, 0.7922],\n",
       "         [0.3569, 0.3843, 0.4157, 0.4510, 0.5098, 0.5412, 0.5804, 0.6078,\n",
       "          0.6392, 0.6196, 0.7725, 0.8235, 0.6863, 0.5098, 0.3490, 0.6706,\n",
       "          0.7137, 0.4941, 0.3686, 0.6667, 0.7843, 0.7686, 0.7804, 0.7843,\n",
       "          0.7922, 0.7961, 0.8000, 0.8000],\n",
       "         [0.3608, 0.3882, 0.4157, 0.4627, 0.5216, 0.5490, 0.5961, 0.6078,\n",
       "          0.6392, 0.6314, 0.8353, 0.7843, 0.7765, 0.7137, 0.7490, 0.7451,\n",
       "          0.7216, 0.4549, 0.5490, 0.8039, 0.7647, 0.7843, 0.7882, 0.7922,\n",
       "          0.7922, 0.7961, 0.8078, 0.8118],\n",
       "         [0.3608, 0.3922, 0.4157, 0.4706, 0.5294, 0.5608, 0.5765, 0.6196,\n",
       "          0.6627, 0.6941, 0.7804, 0.7961, 0.8078, 0.7882, 0.7490, 0.6980,\n",
       "          0.6118, 0.4039, 0.4980, 0.8118, 0.7647, 0.7843, 0.7922, 0.7961,\n",
       "          0.8039, 0.8118, 0.8118, 0.8157],\n",
       "         [0.3686, 0.3922, 0.4196, 0.4784, 0.5333, 0.5451, 0.6471, 0.7843,\n",
       "          0.7412, 0.7333, 0.7451, 0.7922, 0.7686, 0.7216, 0.6784, 0.6314,\n",
       "          0.4588, 0.3176, 0.5490, 0.8078, 0.7725, 0.7882, 0.7961, 0.8039,\n",
       "          0.8118, 0.8196, 0.8196, 0.8235],\n",
       "         [0.3725, 0.4000, 0.4235, 0.4863, 0.5333, 0.5412, 0.7804, 0.7255,\n",
       "          0.6745, 0.6941, 0.7490, 0.7725, 0.7490, 0.7373, 0.7059, 0.6000,\n",
       "          0.4039, 0.2588, 0.5490, 0.8392, 0.7804, 0.7922, 0.7961, 0.8118,\n",
       "          0.8196, 0.8196, 0.8275, 0.8275],\n",
       "         [0.3765, 0.4039, 0.4314, 0.5059, 0.5176, 0.6510, 0.7961, 0.6549,\n",
       "          0.6431, 0.6824, 0.6824, 0.6510, 0.6157, 0.6235, 0.5176, 0.4745,\n",
       "          0.3294, 0.2353, 0.5059, 0.7882, 0.7804, 0.7961, 0.8275, 0.8157,\n",
       "          0.8196, 0.8275, 0.8314, 0.8353],\n",
       "         [0.3765, 0.4078, 0.4392, 0.5059, 0.5059, 0.8392, 0.8392, 0.7412,\n",
       "          0.7373, 0.7529, 0.7137, 0.6941, 0.6667, 0.6196, 0.4039, 0.3647,\n",
       "          0.2745, 0.4157, 0.4196, 0.3882, 0.4627, 0.4902, 0.6980, 0.8431,\n",
       "          0.8196, 0.8353, 0.8314, 0.8392],\n",
       "         [0.3804, 0.4078, 0.4392, 0.4980, 0.5412, 0.9098, 0.7961, 0.7490,\n",
       "          0.6980, 0.6471, 0.6510, 0.6706, 0.6627, 0.5529, 0.3804, 0.3255,\n",
       "          0.2784, 0.4392, 0.4275, 0.3412, 0.3569, 0.4392, 0.4431, 0.8118,\n",
       "          0.8392, 0.8353, 0.8392, 0.8431],\n",
       "         [0.3882, 0.4118, 0.4471, 0.5059, 0.5647, 0.8314, 0.7490, 0.6824,\n",
       "          0.6157, 0.5255, 0.4588, 0.5412, 0.5412, 0.5216, 0.3843, 0.3333,\n",
       "          0.2549, 0.3490, 0.4196, 0.3451, 0.3765, 0.4510, 0.4157, 0.7922,\n",
       "          0.8471, 0.8392, 0.8471, 0.8471],\n",
       "         [0.3922, 0.4157, 0.4549, 0.5098, 0.5804, 0.8118, 0.7412, 0.6314,\n",
       "          0.5098, 0.4471, 0.3490, 0.2157, 0.4118, 0.5373, 0.3922, 0.3804,\n",
       "          0.2235, 0.1882, 0.3529, 0.3765, 0.3843, 0.3647, 0.4706, 0.8549,\n",
       "          0.8392, 0.8471, 0.8510, 0.8510],\n",
       "         [0.4000, 0.4196, 0.4667, 0.5059, 0.5922, 0.8078, 0.7412, 0.6196,\n",
       "          0.4863, 0.3765, 0.2000, 0.3216, 0.5176, 0.5647, 0.4039, 0.2706,\n",
       "          0.1686, 0.1686, 0.2392, 0.3882, 0.4118, 0.3569, 0.5922, 0.8745,\n",
       "          0.8353, 0.8549, 0.8549, 0.8549],\n",
       "         [0.4000, 0.4235, 0.4706, 0.5098, 0.5686, 0.8118, 0.7608, 0.6471,\n",
       "          0.5333, 0.4314, 0.2392, 0.3451, 0.3843, 0.3255, 0.2353, 0.1725,\n",
       "          0.2196, 0.2941, 0.2863, 0.3569, 0.4471, 0.3765, 0.7373, 0.8706,\n",
       "          0.8471, 0.8549, 0.8627, 0.8667],\n",
       "         [0.4039, 0.4235, 0.4784, 0.5176, 0.5804, 0.8392, 0.7647, 0.6510,\n",
       "          0.5490, 0.4353, 0.3490, 0.2510, 0.1569, 0.1373, 0.2000, 0.2627,\n",
       "          0.3098, 0.3529, 0.3725, 0.3412, 0.4118, 0.4353, 0.8392, 0.8549,\n",
       "          0.8588, 0.8588, 0.8627, 0.8667],\n",
       "         [0.4078, 0.4275, 0.4824, 0.5098, 0.5961, 0.8784, 0.7529, 0.6549,\n",
       "          0.5529, 0.4627, 0.4235, 0.3608, 0.2078, 0.2431, 0.3216, 0.3686,\n",
       "          0.4118, 0.4275, 0.4196, 0.3961, 0.3451, 0.6353, 0.8863, 0.8510,\n",
       "          0.8627, 0.8667, 0.8627, 0.8667],\n",
       "         [0.4118, 0.4235, 0.4863, 0.5137, 0.5804, 0.8510, 0.7333, 0.6431,\n",
       "          0.5529, 0.4745, 0.4275, 0.3725, 0.2510, 0.3255, 0.4275, 0.4549,\n",
       "          0.4784, 0.4706, 0.4549, 0.3725, 0.5373, 0.8588, 0.8549, 0.8549,\n",
       "          0.8667, 0.8706, 0.8706, 0.8706],\n",
       "         [0.4118, 0.4314, 0.5020, 0.5216, 0.5804, 0.8353, 0.7098, 0.6392,\n",
       "          0.5569, 0.4863, 0.4196, 0.3686, 0.2824, 0.3529, 0.4431, 0.4588,\n",
       "          0.4510, 0.4588, 0.4078, 0.4627, 0.8588, 0.8471, 0.8510, 0.8627,\n",
       "          0.8627, 0.8667, 0.8824, 0.8824],\n",
       "         [0.4118, 0.4314, 0.5020, 0.5137, 0.6157, 0.8196, 0.7137, 0.6353,\n",
       "          0.5647, 0.4863, 0.4157, 0.3686, 0.3176, 0.3882, 0.4314, 0.4353,\n",
       "          0.4353, 0.4431, 0.3647, 0.6980, 0.8745, 0.8471, 0.8706, 0.8745,\n",
       "          0.8745, 0.8784, 0.8863, 0.8863],\n",
       "         [0.4078, 0.4314, 0.5059, 0.5020, 0.6824, 0.7961, 0.6706, 0.6078,\n",
       "          0.5412, 0.4706, 0.4078, 0.3922, 0.3529, 0.4000, 0.4235, 0.4353,\n",
       "          0.4392, 0.3608, 0.5569, 0.8627, 0.8471, 0.8667, 0.8706, 0.8784,\n",
       "          0.8863, 0.8941, 0.8980, 0.8980],\n",
       "         [0.4118, 0.4353, 0.5137, 0.5020, 0.7882, 0.7647, 0.6510, 0.5882,\n",
       "          0.5294, 0.4745, 0.4275, 0.4039, 0.3686, 0.3843, 0.4196, 0.4118,\n",
       "          0.3725, 0.5451, 0.8392, 0.8549, 0.8549, 0.8667, 0.8745, 0.8784,\n",
       "          0.8863, 0.8941, 0.8980, 0.8980],\n",
       "         [0.4118, 0.4392, 0.5098, 0.5373, 0.8078, 0.7137, 0.6588, 0.5961,\n",
       "          0.5255, 0.4902, 0.4392, 0.4118, 0.3725, 0.3647, 0.3804, 0.4118,\n",
       "          0.6549, 0.8588, 0.8431, 0.8510, 0.8588, 0.8706, 0.8863, 0.8863,\n",
       "          0.8902, 0.8941, 0.8980, 0.9020],\n",
       "         [0.4118, 0.4431, 0.5059, 0.5765, 0.7882, 0.6627, 0.6353, 0.6039,\n",
       "          0.5176, 0.4588, 0.4039, 0.3882, 0.3804, 0.3647, 0.3922, 0.7216,\n",
       "          0.8471, 0.8392, 0.8471, 0.8549, 0.8706, 0.8745, 0.8824, 0.8863,\n",
       "          0.8941, 0.9020, 0.9020, 0.9020],\n",
       "         [0.4157, 0.4588, 0.4824, 0.6627, 0.7647, 0.6314, 0.5882, 0.5529,\n",
       "          0.5176, 0.4392, 0.3804, 0.3647, 0.3686, 0.3294, 0.5569, 0.8392,\n",
       "          0.8196, 0.8431, 0.8549, 0.8627, 0.8667, 0.8745, 0.8863, 0.8941,\n",
       "          0.8980, 0.9020, 0.9020, 0.9020]]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img, lbl = dataset_train[23]\n",
    "img\n",
    "\n",
    "# from matplotlib import pyplot as plt\n",
    "# plt.imshow(img.permute(1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "429 113\n",
      "64 64\n"
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset_train, batch_size=64, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(dataset_test, batch_size=64, shuffle=False)\n",
    "\n",
    "print(len(train_loader), len(val_loader))\n",
    "print(len([(imgs, labels) for imgs, labels in train_loader][0][0]),\n",
    "      len([(imgs, labels) for imgs, labels in val_loader][0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class NetDropout(nn.Module):\n",
    "    def __init__(self, n = 32):\n",
    "        super().__init__()\n",
    "        self.n = n\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(1, self.n, kernel_size=3, padding=1)\n",
    "        self.conv1_dropout = nn.Dropout2d(p=0.3)\n",
    "        self.conv2 = nn.Conv2d(self.n, (self.n//2), kernel_size=3, padding=1)\n",
    "        self.conv2_dropout = nn.Dropout2d(p=0.3)\n",
    "        self.conv3 = nn.Conv2d((self.n//2), (self.n//2), kernel_size=3, padding=1)\n",
    "        self.conv3_dropout = nn.Dropout2d(p=0.3)\n",
    "\n",
    "        self.fc1 = nn.Linear((self.n//2)*3*3, 32)\n",
    "        self.fc2 = nn.Linear(32, 25)\n",
    "        \n",
    "        self.lsftmx = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.max_pool2d(torch.tanh(self.conv1(x)), 2)\n",
    "        out = self.conv1_dropout(out)\n",
    "        out = F.max_pool2d(torch.tanh(self.conv2(out)), 2)\n",
    "        out = self.conv2_dropout(out)\n",
    "        out = F.max_pool2d(torch.tanh(self.conv3(out)), 2)\n",
    "        out = self.conv3_dropout(out)\n",
    "\n",
    "        out = out.view(-1, (self.n//2)*3*3)\n",
    "        out = torch.tanh(self.fc1(out))\n",
    "        out = self.lsftmx(self.fc2(out))\n",
    "        return out\n",
    "    \n",
    "# class NetVarSize(nn.Module):\n",
    "#     def __init__(self, n = 32):\n",
    "#         super().__init__()\n",
    "#         self.n = n\n",
    "        \n",
    "#         self.conv1 = nn.Conv2d(1, self.n, kernel_size=3, padding=1)\n",
    "#         self.conv1_dropout = nn.Dropout2d(p=0.3)\n",
    "#         self.conv2 = nn.Conv2d(self.n, (self.n//2), kernel_size=3, padding=1)\n",
    "#         self.conv2_dropout = nn.Dropout2d(p=0.3)\n",
    "#         self.conv3 = nn.Conv2d((self.n//2), (self.n//2), kernel_size=3, padding=1)\n",
    "#         self.conv3_dropout = nn.Dropout2d(p=0.3)\n",
    "\n",
    "#         self.fc1 = nn.Linear((self.n//2)*3*3, 32)\n",
    "#         self.fc2 = nn.Linear(32, 25)\n",
    "        \n",
    "#         self.lsftmx = nn.LogSoftmax(dim=1)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         out = F.adaptive_max_pool2d(torch.tanh(self.conv1(x)), (2, 2))\n",
    "#         out = self.conv1_dropout(out)\n",
    "#         out = F.adaptive_max_pool2d(torch.tanh(self.conv2(out)), (2, 2))\n",
    "#         out = self.conv2_dropout(out)\n",
    "#         out = F.adaptive_max_pool2d(torch.tanh(self.conv3(out)), (2, 2))\n",
    "#         out = self.conv3_dropout(out)\n",
    "\n",
    "#         out = out.view(out.size(0), -1)\n",
    "#         out = torch.tanh(self.fc1(out))\n",
    "#         out = self.fc2(out)\n",
    "#         out = self.lsftmx(out)\n",
    "#         return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(n_epochs, model, loss_fn, optimizer, train_loader, device):\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        for (imgs, labels) in train_loader:\n",
    "            imgs = imgs.to(device=device)\n",
    "            labels = labels.to(device=device)\n",
    "\n",
    "            outs = model(imgs)\n",
    "            loss = loss_fn(outs, labels)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        if epoch % 10 == 0 or epoch <= 3:\n",
    "            print(\"epoch=%d loss=%f\" %(epoch, loss)) # loss of last batch\n",
    "\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    for imgs, labels in train_loader:\n",
    "        imgs = imgs.to(device=device)\n",
    "        labels = labels.to(device=device)\n",
    "\n",
    "        outs = model(imgs)\n",
    "        max_vals, max_classes = outs.max(dim=1)\n",
    "\n",
    "        total += imgs.shape[0]\n",
    "        correct += (max_classes == labels).sum()\n",
    "\n",
    "    print(\"training accuracy =%f\" %(correct/total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, loader, device):\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    for (imgs, lbls) in loader:\n",
    "        imgs = imgs.to(device=device)\n",
    "        lbls = lbls.to(device=device)\n",
    "\n",
    "        outs = model(imgs)\n",
    "        max_vals, max_indexes = outs.max(dim=1)\n",
    "        \n",
    "        correct += ((max_indexes == lbls).sum())\n",
    "        total += imgs.shape[0]\n",
    "    print(\"accuracy %f\" %(correct/total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=1 loss=3.209289\n",
      "epoch=2 loss=3.179486\n",
      "epoch=3 loss=3.206956\n",
      "epoch=10 loss=2.290270\n",
      "epoch=20 loss=1.206905\n",
      "epoch=30 loss=0.509000\n",
      "epoch=40 loss=0.506229\n",
      "epoch=50 loss=0.274397\n",
      "epoch=60 loss=0.270535\n",
      "epoch=70 loss=0.195263\n",
      "epoch=80 loss=0.291559\n",
      "epoch=90 loss=0.114831\n",
      "epoch=100 loss=0.131022\n",
      "training accuracy =0.955746\n",
      "accuracy 0.850390\n"
     ]
    }
   ],
   "source": [
    "# import torch.optim as optim\n",
    "# import os\n",
    "\n",
    "# device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "# model = NetDropout().to(device=device)\n",
    "\n",
    "# training_loop(\n",
    "#     n_epochs=100,\n",
    "#     model=model,\n",
    "#     train_loader=train_loader,\n",
    "#     loss_fn=nn.NLLLoss(),\n",
    "#     optimizer=optim.SGD(model.parameters(), lr=0.01),\n",
    "#     device=device\n",
    "# )\n",
    "\n",
    "# validate(model, val_loader, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.save(model.state_dict(), \"./model.t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (64x64 and 144x32)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[92], line 7\u001B[0m\n\u001B[0;32m      4\u001B[0m device \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mdevice(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcuda\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;28;01mif\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mcuda\u001B[38;5;241m.\u001B[39mis_available() \u001B[38;5;28;01melse\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mdevice(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcpu\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m      5\u001B[0m model2 \u001B[38;5;241m=\u001B[39m NetVarSize()\u001B[38;5;241m.\u001B[39mto(device\u001B[38;5;241m=\u001B[39mdevice)\n\u001B[1;32m----> 7\u001B[0m training_loop(\n\u001B[0;32m      8\u001B[0m     n_epochs\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m100\u001B[39m,\n\u001B[0;32m      9\u001B[0m     model\u001B[38;5;241m=\u001B[39mmodel2,\n\u001B[0;32m     10\u001B[0m     train_loader\u001B[38;5;241m=\u001B[39mtrain_loader,\n\u001B[0;32m     11\u001B[0m     loss_fn\u001B[38;5;241m=\u001B[39mnn\u001B[38;5;241m.\u001B[39mNLLLoss(),\n\u001B[0;32m     12\u001B[0m     optimizer\u001B[38;5;241m=\u001B[39moptim\u001B[38;5;241m.\u001B[39mSGD(model2\u001B[38;5;241m.\u001B[39mparameters(), lr\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.01\u001B[39m),\n\u001B[0;32m     13\u001B[0m     device\u001B[38;5;241m=\u001B[39mdevice\n\u001B[0;32m     14\u001B[0m )\n\u001B[0;32m     16\u001B[0m validate(model2, val_loader, device\u001B[38;5;241m=\u001B[39mdevice)\n",
      "Cell \u001B[1;32mIn[36], line 7\u001B[0m, in \u001B[0;36mtraining_loop\u001B[1;34m(n_epochs, model, loss_fn, optimizer, train_loader, device)\u001B[0m\n\u001B[0;32m      4\u001B[0m imgs \u001B[38;5;241m=\u001B[39m imgs\u001B[38;5;241m.\u001B[39mto(device\u001B[38;5;241m=\u001B[39mdevice)\n\u001B[0;32m      5\u001B[0m labels \u001B[38;5;241m=\u001B[39m labels\u001B[38;5;241m.\u001B[39mto(device\u001B[38;5;241m=\u001B[39mdevice)\n\u001B[1;32m----> 7\u001B[0m outs \u001B[38;5;241m=\u001B[39m model(imgs)\n\u001B[0;32m      8\u001B[0m loss \u001B[38;5;241m=\u001B[39m loss_fn(outs, labels)\n\u001B[0;32m     10\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n",
      "File \u001B[1;32mc:\\IT\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1531\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1532\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32mc:\\IT\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1536\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1537\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1538\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1539\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1540\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1541\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1543\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1544\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "Cell \u001B[1;32mIn[91], line 60\u001B[0m, in \u001B[0;36mNetVarSize.forward\u001B[1;34m(self, x)\u001B[0m\n\u001B[0;32m     57\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconv3_dropout(out)\n\u001B[0;32m     59\u001B[0m out \u001B[38;5;241m=\u001B[39m out\u001B[38;5;241m.\u001B[39mview(out\u001B[38;5;241m.\u001B[39msize(\u001B[38;5;241m0\u001B[39m), \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m---> 60\u001B[0m out \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mtanh(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfc1(out))\n\u001B[0;32m     61\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfc2(out)\n\u001B[0;32m     62\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlsftmx(out)\n",
      "File \u001B[1;32mc:\\IT\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1531\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1532\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32mc:\\IT\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1536\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1537\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1538\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1539\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1540\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1541\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1543\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1544\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32mc:\\IT\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:116\u001B[0m, in \u001B[0;36mLinear.forward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    115\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[1;32m--> 116\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m F\u001B[38;5;241m.\u001B[39mlinear(\u001B[38;5;28minput\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mweight, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbias)\n",
      "\u001B[1;31mRuntimeError\u001B[0m: mat1 and mat2 shapes cannot be multiplied (64x64 and 144x32)"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "import os\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "model2 = NetVarSize().to(device=device)\n",
    "\n",
    "training_loop(\n",
    "    n_epochs=100,\n",
    "    model=model2,\n",
    "    train_loader=train_loader,\n",
    "    loss_fn=nn.NLLLoss(),\n",
    "    optimizer=optim.SGD(model2.parameters(), lr=0.01),\n",
    "    device=device\n",
    ")\n",
    "\n",
    "validate(model2, val_loader, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "torch.save(model2.state_dict(), \"./model2.t\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
